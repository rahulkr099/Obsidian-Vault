Alright Rahul, here comes a **clean, interview-quality backend machine coding round question** for **Short Polling / Long Polling â€“ Detecting State Changes**.

This is a classic backend problem where interviewers test your understanding of **real-time-ish communication**, **event detection**, **server efficiency**, and **state polling patterns**.

Iâ€™ll keep it super clear, friendly, and forward-thinking.

---

# ğŸ§‡ **Backend Machine Coding Round â€” Short Polling / Long Polling System**

### â± Time Limit: 45â€“60 minutes

### ğŸ¯ Goal

Build a backend API that lets clients detect **state changes** using either:

- **Short Polling** (simple repeated polling), or
    
- **Long Polling** (server holds connection until data changes)
    

This tests async flow, event detection, response waiting, and efficient server design.

---

# ğŸ“ **Problem Statement**

Design a backend system where a **client polls the server to detect when a resource changes**.

For example:  
A user is waiting for their **order status** or **job status** to change from `pending â†’ completed`.

System should support:

- Short polling (return instantly)
    
- Long polling (hold request until state changes or timeout)
    
- Clean detection logic
    
- Race condition handling
    
- Timeout handling
    

You may use **Node.js + Express**.

---

# ğŸ“¦ **Resource Model Example**

Letâ€™s track **job status**:

```json
{
  "id": "job_123",
  "status": "pending",   // pending, processing, done
  "updatedAt": "timestamp"
}
```

---

# ğŸ”§ **Required Endpoints**

### 1. Create job

```
POST /jobs
```

### 2. Update job status (simulate external system)

```
PUT /jobs/:id
```

### 3. Poll job status (short polling)

```
GET /jobs/:id/status?mode=short
```

### 4. Poll job status (long polling)

```
GET /jobs/:id/status?mode=long&timeout=10000
```

---

# ğŸ’¡ **Functional Requirements**

## **1ï¸âƒ£ Create Job**

Input:

```json
{
  "id": "job_123"
}
```

Creates job with:

- status = `"pending"`
    
- updatedAt = now
    

---

## **2ï¸âƒ£ Update Job Status**

Input:

```json
{
  "status": "done"
}
```

Updates:

- status
    
- updatedAt
    

---

## **3ï¸âƒ£ Short Polling (mode=short)**

Returns immediately:

### Response:

```json
{
  "id": "job_123",
  "status": "pending"
}
```

Simple, fast, but inefficient.

---

## **4ï¸âƒ£ Long Polling (mode=long)**

Behavior:

1. Client sends request with a timeout:
    
    ```
    GET /jobs/job_123/status?mode=long&timeout=15000
    ```
    
2. Server:
    
    - Checks status now
        
    - If status already changed â†’ return immediately
        
    - Else:
        
        - HOLD request
            
        - Wait until:
            
            - status changes
                
            - OR timeout reached
                
3. On change:  
    Return:
    
    ```json
    {
      "id": "job_123",
      "status": "done",
      "message": "Status changed"
    }
    ```
    
4. On timeout:
    
    ```json
    {
      "id": "job_123",
      "status": "pending",
      "message": "No change"
    }
    ```
    

---

# ğŸ§ª **Edge Cases to Handle**

- Job not found â†’ 404
    
- Invalid mode â†’ 400
    
- Timeout < 1000 ms â†’ enforce minimum
    
- Long polling request disconnects â†’ clean up event listeners
    
- Multiple long polls waiting for same job â†’ handle all
    
- Status updates before client polls â†’ must return correct value
    
- Long polling must **not block main thread**
    
- Prevent memory leaks:
    
    - remove listeners when done
        
- Race condition:
    
    - status updated _while_ checking â†’ detect correctly
        

---

# ğŸ§± **Backend Logic Requirements**

- Long polling must use:
    
    - `setTimeout`
        
    - event emitters
        
    - or Promise-based wait loops
        
- Must track:
    
    - waiting clients
        
    - job update events
        
- Clean cancellation when:
    
    - client disconnects
        
    - timeout hits
        

---

# ğŸ“Š **Expected Behaviour**

### Short polling:

- Returns instantly
    
- Client will spam server every few seconds
    

### Long polling:

- Returns only when job changes
    
- Saves server load
    
- Gives near-real-time effect
    

---

# â­ **Interviewer Follow-Up Questions**

1. Difference between **short polling**, **long polling**, **WebSockets**, and **Server-Sent Events**?
    
2. When should you prefer long polling over WebSockets?
    
3. How do you manage thousands of long polling connections?
    
4. How do you prevent memory leaks when holding requests?
    
5. How do you scale long polling across multiple instances?
    
6. How do you handle:
    
    - Redis pub/sub
        
    - distributed event notifications
        
    - load balancers
        
7. How would you convert this to **WebSockets** later?
    

---

# ğŸŒŸ **Bonus Features (Great to Impress)**

- Add event-driven system using:
    
    - Node.js EventEmitter
        
    - Redis Pub/Sub
        
    - Kafka topics
        
- Add job types (email, file upload, processing)
    
- Add exponential backoff for short polling
    
- Add rate limit per client
    
- Support multi-field change detection
    
- Add caching for job state
    
- Add `/subscribe` endpoint for SSE (Server-Sent Events)
    

---

If you want, I can generate the next one:

â¡ï¸ **20. Real-time Chat Backend (WebSocket)**  
â¡ï¸ **21. Nested Comments System**  
â¡ï¸ **22. Social Feed Backend**  
â¡ï¸ **23. Notification/Webhook System**

Just tell me the next round!