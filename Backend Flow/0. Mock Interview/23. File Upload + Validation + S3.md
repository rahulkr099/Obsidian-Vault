Alright Rahul, here is a **strong, interview-ready backend machine coding round mock question** for **File Upload + Validation + S3 Storage**.  
This is one of the most **practical and commonly asked** tasks for backend engineers because it tests:

- multipart uploads
    
- MIME/type validation
    
- size validation
    
- S3 SDK usage
    
- security
    
- clean API design
    
- error handling
    

Iâ€™ll keep it simple, friendly, and forward-thinking.

---

# ğŸª£ **Backend Machine Coding Round â€” File Upload + Validation + S3 Storage**

### â± Time Limit: 45â€“60 minutes

### ğŸ¯ Goal

Build a file-upload backend with:

- Upload endpoint
    
- Local validation (size, type)
    
- Upload to AWS S3
    
- Return public/signed URL
    
- Proper error handling
    
- Secure file naming
    

---

# ğŸ“ **Problem Statement**

Create a backend service that accepts a file upload from a client (multipart/form-data), validates the file, uploads it to **Amazon S3**, and returns the uploaded fileâ€™s URL.

You must handle:

- File type validation
    
- File size validation
    
- Unique filename generation
    
- Uploading binary data to S3
    
- Error handling & safe failure responses
    

Use **Node.js + Express + Multer/AWS SDK** or any equivalent setup.

---

# ğŸ“¦ **Functional Requirements**

## **1ï¸âƒ£ Endpoint â€” POST /upload**

Request:

```
Content-Type: multipart/form-data
Field name: file
```

The API should:

### âœ” Accept exactly one file

### âœ” Validate file type

Allowed types (example):

- image/jpeg
    
- image/png
    
- application/pdf
    

### âœ” Validate file size

Rules:

- Maximum size = **5 MB**
    
- If exceeded â†’ return **413 Payload Too Large**
    

### âœ” Secure the file name

- Generate internal filename (UUID)
    
- Keep original extension
    
- Prevent path traversal (`../../../etc/passwd`)
    

### âœ” Upload file to S3

- Use S3 PutObject
    
- Bucket name from environment variable
    
- ACL optional (private recommended)
    

### âœ” Return a URL

Clients receive:

- S3 public URL OR
    
- Pre-signed GET URL
    

Example response:

```json
{
  "success": true,
  "fileName": "e3f29f.png",
  "url": "https://my-bucket.s3.amazonaws.com/e3f29f.png",
  "size": 234523
}
```

---

# ğŸ§ª **Edge Cases to Handle**

- Missing file â†’ return 400
    
- Wrong field name (not `file`) â†’ 400
    
- File too large â†’ 413
    
- Unsupported type â†’ 400
    
- Malicious filenames â†’ sanitize
    
- Empty file â†’ reject
    
- S3 upload failure â†’ return 500
    
- Connectivity issues â†’ retry logic (optional)
    
- Bucket permissions incorrect â†’ safe error response
    
- File with no extension â†’ handle gracefully
    
- Two users uploading at exact same time â†’ ensure unique names
    
- Very large memory usage â†’ use stream upload, not buffer (bonus)
    

---

# ğŸ”’ **Security Requirements**

- Do NOT trust client-provided MIME type (double-verify on backend)
    
- Validate extension + MIME + magic bytes (bonus)
    
- Never store file with user-given path
    
- Use S3 private bucket + presigned URLs (recommended)
    
- Limit file size to prevent DOS attacks
    
- Disable execution permissions on uploaded files
    
- Reject dangerous file types: `.exe`, `.sh`, `.bat`
    

---

# ğŸ”§ **Backend Design Requirements**

- Use clean architecture:
    
    - controller
        
    - service
        
    - AWS S3 module
        
    - validation helpers
        
- Use environment variables for:
    
    - AWS_ACCESS_KEY
        
    - AWS_SECRET_KEY
        
    - AWS_REGION
        
    - S3_BUCKET
        
- Code must separate:
    
    - upload handling
        
    - validations
        
    - S3 logic
        

---

# â˜ï¸ **S3 Upload Flow (Expected Explanation)**

1. Receive file via Multer (diskStorage or memoryStorage)
    
2. Validate file
    
3. Generate unique name
    
4. Convert file into buffer or stream
    
5. Call:
    
    ```js
    s3.upload({
      Bucket,
      Key,
      Body,
      ContentType
    })
    ```
    
6. On success â†’ respond with URL
    
7. On failure â†’ delete local file (if any) and return safe error
    

---

# âš™ï¸ **Bonus Advanced Requirements (Optional)**

### **1. Presigned URL Upload Flow**

Instead of uploading via backend, generate:

```
POST /upload-url
```

Return:

```json
{
  "url": "<presigned-url>",
  "fileKey": "a23f9.png"
}
```

Client uploads directly â†’ saves backend bandwidth.

### **2. Multiple File Uploads**

Support:

```
files[] = [...]
```

### **3. S3 Folder Structure**

Organize uploads by user:

```
user_123/profile/pic.png
user_123/uploads/doc.pdf
```

### **4. File delete endpoint**

```
DELETE /file/:key
```

---

# â­ **Interviewer Follow-Up Questions**

1. Why use **presigned URLs** instead of uploading via backend?
    
2. What is the difference between:
    
    - memory storage vs disk storage in Multer?
        
3. How do you ensure file types are safe?
    
4. How do you design a virus scan pipeline for uploads?
    
5. How do you compress or resize images before uploading?
    
6. How to handle very large files (streaming, chunk upload)?
    
7. How to enable CDN caching via CloudFront?
    
8. How do you make uploads resumable (like Google Drive)?
    
9. What happens if S3 upload is slow or times out?
    
10. How would you track upload progress?
    

---

# ğŸŒŸ **Bonus Features (For Extra Points)**

- Thumbnails/preview generation
    
- Image optimization using Sharp
    
- Video transcoding
    
- Rate-limiting file uploads
    
- Upload history tracking
    
- MIME sniffing using `file-type` package
    
- Auto-delete after X days (cron cleanup)
    

---

If you want, I can prepare the next machine coding round:

â¡ï¸ **Searchable Blog Backend**  
â¡ï¸ **User Profile System**  
â¡ï¸ **Document Management System**  
â¡ï¸ **CSV Import + Processing  
â¡ï¸ Analytics Event Collector System**

Just tell me the next one, Rahul!